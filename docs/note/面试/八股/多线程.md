## 多线程面试题

### Synchronized用过吗？原理是什么

`Synchronized`是JVM实现同步互斥的一种方式，被Synchronized修饰的方法或代码块，编译后的字节码中有`monitorenter`和`monitorexit`指令，JVM通过这两个指令来实现锁的获取和释放。
执行到monitorenter时，尝试获取锁，获取锁成功之后，计数器+1，执行monitorexit后，计数器-1，计数器为0时，释放锁。
通过在对象头设置标记，达到获取锁释放锁的目的。

    每个对象的头部都有一个用于存储锁信息的字段，称为 Mark Word

### JVM 对 `synchronized` 的优化

1. **锁的粒度优化：**
   - JVM 会根据程序情况选择锁的粒度，可能合并多个同步块以减少锁的竞争。

2. **锁的升级：**
   - 锁有多个状态，JVM 根据竞争情况进行升级，可能从偏向锁（对象头中记录获取锁的线程ID）到轻量级锁（CAS修改对象头标记中锁标记位）或重量级锁（NOTIFY）。

3. **锁的消除：**
   - JVM 可通过静态分析判断不会发生竞争的同步块，将其中的锁消除以减少同步开销。

4. **适应性自旋：**
   - JVM 动态调整自旋次数，提高性能。长时间无竞争的同步块可能增加自旋次数，避免进入重量级锁状态。

### 悲观锁和乐观锁定义

悲观锁（Pessimistic Locking）：

- 定义： 悲观锁是一种悲观地认为在一段时间内，会有其他线程来竞争共享资源的锁。因此，在访问共享资源之前，悲观锁会先获取锁，确保同一时间只有一个线程能够访问共享资源。

- 实现： 通常通过互斥量（Mutex）或者同步关键字（如Java中的synchronized）来实现。在进入临界区之前，线程会先获取锁，如果锁被其他线程持有，则当前线程会被阻塞。

- 优点： 简单易用，确保同一时间只有一个线程访问共享资源，避免了并发冲突。

- 缺点： 在高并发情况下，可能导致线程阻塞，降低系统吞吐量。过多的加锁和解锁操作可能引起性能问题。

乐观锁（Optimistic Locking）：

- 定义： 乐观锁是一种乐观地认为在一段时间内，不会有其他线程来竞争共享资源的锁。因此，线程在访问共享资源之前，并不立即获取锁，而是直接进行操作。在更新共享资源时，会检查是否有其他线程对资源进行了修改。

- 实现： 通常通过版本号、时间戳等方式实现。在读取共享资源时，记录版本号；在写入共享资源时，检查当前的版本号是否仍然是最新的。

- 优点： 在低并发情况下，不会引起线程阻塞，性能较好。只有在发生冲突时，才进行额外的处理。

- 缺点： 需要额外的版本控制机制，可能需要解决冲突的问题，适用于较为乐观的并发场景。

### Synchronized 和 ReentrantLock 的异同

共同点：实现线程同步，可重入性

不同点：

- 等待可中断，长时间获取不到锁可以放弃等待
- ReentrantLock可以响应中断请求，在等待锁的过程中，如果线程被中断，可以通过调用 lockInterruptibly() 方法中断等待。
- 锁释放：Synchronized由jvm负责释放，ReentrantLock由用户代码负责释放

### ReentrantLock是如何实现可重入性的？

实现可重入性的主要机制是使用一个计数器（holdCount）来记录当前线程持有锁的次数。

### CyclicBarrier和CountDownLatch异同

**相同点：**

1. 同步点： 两者都可以用于创建同步点，使多个线程在某个位置同步执行。

2. 线程等待： 在两者的作用下，线程可以等待其他线程的到达。

**不同点：**

1. 复用性：
    - CyclicBarrier： 可以被重用。一旦所有线程都到达屏障点，它会被重置，可以被再次使用。
    - CountDownLatch： 不能被重用。一旦计数器达到零，就不能再次恢复。

2. 计数器减少：
    - CyclicBarrier： 内部维护一个计数器，每个线程到达时计数器减1，当计数器为零时，释放所有等待的线程。
    - CountDownLatch： 内部也维护一个计数器，但是只有 countDown() 方法来递减计数器。

3. 线程到达时机：
    - CyclicBarrier： 线程在到达屏障点后会调用 await() 方法等待其他线程，直到所有线程都到达，屏障才会打开。
    - CountDownLatch： 每个线程通过 countDown() 方法递减计数器，当计数器为零时，所有线程可以通过 await() 方法继续执行。

3. 任务分工：
    - CyclicBarrier： 适用于任务分工协作的场景，各个线程可以分别执行任务，然后在屏障点同步。
    - CountDownLatch： 适用于一组线程需要等待另一组线程执行完毕后再同时开始执行的场景。

4. 异常处理：
    - CyclicBarrier： 可以提供一个可选的 Runnable 参数，在所有线程到达屏障后执行该任务。
    - CountDownLatch： 不提供类似的机制。

### 创建线程池的几个核心构造参数

1. `corePoolSize（核心线程数）：`
    - 定义了线程池的核心线程数，即线程池中一直存活的线程数量。
    - 当有任务提交时，如果当前线程数小于核心线程数，会创建新的线程来执行任务。
2. `maximumPoolSize（最大线程数）：`
    - 定义了线程池中允许存在的最大线程数。
    - 当队列满了且当前线程数小于最大线程数时，会创建新的线程来执行任务。
    - 达到最大线程数后，后续的任务会被放入任务队列等待执行。
3. `keepAliveTime（线程空闲时间）：`
    - 定义了非核心线程的空闲时间，超过这个时间，多余的非核心线程会被回收。
    - 当线程数大于核心线程数时，如果一个线程在空闲时间内没有执行任务，就会被终止。
4. `unit（时间单位）：`
    - 与 keepAliveTime 配合使用，定义了空闲时间的时间单位。
5. `workQueue（任务队列）：`
    - 定义了用于保存等待执行任务的阻塞队列。
    - 当线程数达到核心线程数时，新提交的任务会被放入这个队列中等待执行。
    - 任务队列的选择影响了线程池的行为，例如 LinkedBlockingQueue、ArrayBlockingQueue 等。
6. `threadFactory（线程工厂）：`
    - 用于创建新线程的工厂，可以自定义线程的创建过程，例如设置线程的命名规则、优先级等。
7. `handler（拒绝策略）：`
    - 定义了当任务无法被提交执行时的处理策略。
    - 默认提供了几种策略，例如抛出异常、丢弃任务(默认情况)等。也可以自定义实现 RejectedExecutionHandler 接口。

    ```java
    import java.util.concurrent.*;

    public class CustomThreadPool {
        public static void main(String[] args) {
            int corePoolSize = 5;
            int maximumPoolSize = 10;
            long keepAliveTime = 5000;
            TimeUnit unit = TimeUnit.MILLISECONDS;
            BlockingQueue<Runnable> workQueue = new LinkedBlockingQueue<>();
            ThreadFactory threadFactory = Executors.defaultThreadFactory();
            RejectedExecutionHandler handler = new ThreadPoolExecutor.  AbortPolicy();

            ExecutorService executorService = new ThreadPoolExecutor(
                    corePoolSize,
                    maximumPoolSize,
                    keepAliveTime,
                    unit,
                    workQueue,
                    threadFactory,
                    handler
            );

        // 使用线程池执行任务
        executorService.execute(() -> {
            // 任务逻辑
        });

        // 关闭线程池
        executorService.shutdown();
        }
    }

    ```

### 线程池创建

1. `Executors.newFixedThreadPool(int n)` - 固定大小的线程池,适用于执行长期任务的应用程序，限制线程的数量可以防止资源耗尽。

    ```java
    // LinkedBlockingQueue无界队列
   public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>());
    }
    ```

2. `Executors.newCachedThreadPool()` - 缓存线程池：适用于执行很多短期异步任务的小型应用程序。

    ```java
    // 线程数根据需求自动调整，没有固定的核心线程数。
    public static ExecutorService newCachedThreadPool() {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue<Runnable>());
    }
    ```

3. `Executors.newSingleThreadExecutor()` - 单线程池：适用于需要保证顺序执行的场景，例如任务队列中的任务按照提交的顺序执行。

    ```java
    // 永远只有一个线程，与newFixedThreadPool(1)相比，它不会动态增加线程数量，newFixedThreadPool线程因为异常结束，会创建一个新的线程来替代
    public static ExecutorService newSingleThreadExecutor() {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue<Runnable>()));
    }
    ```

4. `Executors.newScheduledThreadPool(int corePoolSize)` -定时任务线程池：适用于需要定时执行任务的场景，例如定时任务、周期性任务等。

    ```java
    // 线程数根据需求自动调整，没有固定的核心线程数。
    public ScheduledThreadPoolExecutor(int corePoolSize) {
        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
              new DelayedWorkQueue());
    }
    ```

### ThreadPoolExecutor中的饱和策略

1. `AbortPolicy（默认策略）：`
    饱和时抛出 RejectedExecutionException 异常。
    示例：new ThreadPoolExecutor.AbortPolicy()
2. `CallerRunsPolicy：`
    调用者运行策略，新任务由调用线程执行。
    示例：new ThreadPoolExecutor.CallerRunsPolicy()
3. `DiscardPolicy：`
    抛弃策略，新任务被丢弃，不抛出异常。
    示例：new ThreadPoolExecutor.DiscardPolicy()
4. `DiscardOldestPolicy：`
    抛弃最老的任务，将工作队列头部的任务移除，腾出空间给新任务。
    示例：new ThreadPoolExecutor.DiscardOldestPolicy()
5. `自定义饱和策略：`
    你可以实现 RejectedExecutionHandler 接口，自定义饱和策略。通常，你需要实现 rejectedExecution 方法，定义自己的处理逻辑。

    ```java
    RejectedExecutionHandler myCustomPolicy = (r, executor) -> {
    // 自定义处理逻辑
    System.out.println("My custom policy: Task rejected, doing something...");
    // 例如，将任务添加到队列中
    executor.getQueue().offer(r);
    };

    ```

### volatile关键字特点

1. 禁止指令重排序
2. 内存屏障
3. 保证可见性，不保证原子性

### ThreadLocal是怎么解决并发安全的

- 以空间换时间的方式，为 每一个线程维护变量的副本，把共享数据的可见范围限制在同一个线程之内，`ThreadLocal`类中有一个`ThreadLocalMap`，用于存储每一个线程的变量的副本 。
- **使用ThradLocal中ThreadLocalMap的key使用弱引用，需要显式调用remove方法，防止内存泄漏**
  
### T1、T2、T3 三个线程，你怎样保证 T2 在T1 执行完后执行，T3 在T2 执行完后执行？

使用线程join方法

### Java 中wait 和sleep 方法的不同

`wait`释放对象锁，需要其他线程唤醒，而`sleep`不释放锁.
